{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5331ec-7504-4cc3-b027-51f757a0fc4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a208e9-3949-477f-ab11-f131580daa16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c232d87",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TEXT_COLOR = '#313131'\n",
    "LINE_COLORS = ['#00A082', '#F2CC38', '#9B59B6', '#3498DB', '#F39C12']\n",
    "\n",
    "sns.set(\n",
    "    style='darkgrid', \n",
    "    rc={'figure.figsize':(6,4),\n",
    "        'figure.dpi': 150,\n",
    "        'figure.facecolor': 'w', \n",
    "        'legend.facecolor': 'w',\n",
    "        'text.color': TEXT_COLOR,\n",
    "        'font.family': 'Microsoft Sans Serif', # 'Open Sans',\n",
    "        'axes.labelcolor': TEXT_COLOR,\n",
    "        'xtick.color': TEXT_COLOR,\n",
    "        'ytick.color': TEXT_COLOR}\n",
    ")\n",
    "\n",
    "sns.set_palette(sns.color_palette(LINE_COLORS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d921eb0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c05439",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/house-prices-dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb1c621",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the outlier\n",
    "data = data.drop(index=1298, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90bc7b08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting top-predictor columns IMO\n",
    "cols = [\n",
    "    'OverallQual', \n",
    "    'GrLivArea',\n",
    "    'ExterQual',\n",
    "    'GarageCars',\n",
    "    'YearBuilt',\n",
    "    'YearRemodAdd',\n",
    "    'TotRmsAbvGrd',\n",
    "    'Foundation',\n",
    "    'Fireplaces',\n",
    "    'FireplaceQu',\n",
    "    'HeatingQC',\n",
    "    'SalePrice'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8067c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4304611",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def col_to_dummies(df, col):\n",
    "    return pd.concat(\n",
    "        [data, pd.get_dummies(data[col], prefix=col, drop_first=True)], \n",
    "        axis=1\n",
    "    ).drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "556f585e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['FireplaceQu'] = data['FireplaceQu'].map({\n",
    "    np.nan: 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ac04c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['HeatingQC'] = data['HeatingQC'].map({\n",
    "    'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d62b23f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['ExterQual'] = data['ExterQual'].map({\n",
    "    'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85eee07d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = col_to_dummies(data, 'Foundation')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Explore how k-means works"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Apply to raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_cols = data.columns.drop(\"SalePrice\").tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km.fit(data[x_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['cluster'] = km.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data, x='GrLivArea', y='SalePrice', hue='cluster', alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like GrLivArea was the most decisive factor to assign clusters because it is of large numbers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Apply to scaled data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_data = data.drop(\"cluster\", axis=1).copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_data[x_cols] = scaler.fit_transform(scaled_data[x_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km.fit(scaled_data[x_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_data['cluster'] = km.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(data=scaled_data, x='GrLivArea', y='SalePrice', hue='cluster', alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot principal components of PCA vs clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pcomps = pca.fit_transform(scaled_data[x_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pc_cols = [f\"PC{n+1}\" for n in range(pcomps.shape[1])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_data[pc_cols] = pcomps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(data=scaled_data, x='PC1', y='PC2', hue='cluster', alpha=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(data=scaled_data, x='PC1', y='SalePrice', hue='cluster', alpha=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply k-means on principal components"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km.fit(scaled_data[pc_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_data['pca_cluster'] = km.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(data=scaled_data, x='PC1', y='PC2', hue='pca_cluster', alpha=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we apply clustering with all principal compotents, we get the same resulting clustering labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Use k-means clusters and PCA components as features in cross-validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import clone"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def perform_cross_validation(X, y, model, cv_folds=10, **kwargs):\n",
    "    \"\"\"Run cross-validation with preprocessing on a specified model.\"\"\"\n",
    "    original_model = clone(model)\n",
    "    total_rows = X.shape[0]\n",
    "    metric_track = None\n",
    "    splits = generate_cv_splits(rows=total_rows, cv=cv_folds)\n",
    "\n",
    "    for valid_start, valid_end in splits:\n",
    "        train_idx, valid_idx = get_train_valid_idx(valid_start, valid_end, total_rows=total_rows)\n",
    "        X_train, y_train, X_valid, y_valid = train_valid_split(X, y, train_idx, valid_idx)\n",
    "        X_train, y_train, X_valid, y_valid = preprocess(X_train, X_valid, y_train, y_valid, **kwargs)\n",
    "\n",
    "        # Re-instantiate the provided model\n",
    "        model_ = clone(original_model)\n",
    "        model_ = model_.fit(X_train, y_train)\n",
    "        y_pred_log = model_.predict(X_valid)\n",
    "        y_pred = np.exp(y_pred_log)\n",
    "\n",
    "        # Evaluate and track performance\n",
    "        current_metrics = pd.DataFrame(data=[evaluate_regression(y_valid, y_pred)])\n",
    "        if metric_track is None:\n",
    "            metric_track = current_metrics.copy()\n",
    "        else:\n",
    "            metric_track = pd.concat((metric_track, current_metrics), axis=0) # append the new result\n",
    "\n",
    "    return dict(metric_track.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_cv_splits(rows, cv=10):\n",
    "    \"\"\"Generate a list of start & end idx for cross validation.\"\"\"\n",
    "    step = rows // cv\n",
    "    splits = []\n",
    "    for split in range(0, cv):\n",
    "        start = step*split\n",
    "        end = start+step\n",
    "        splits.append((start,  end))\n",
    "    return splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_train_valid_idx(valid_start_idx, valid_end_idx, total_rows):\n",
    "    \"\"\"Transform validation start and end indexes into a list of training and validation indexes.\"\"\"\n",
    "    valid_idx = np.arange(valid_start_idx, valid_end_idx)\n",
    "    all_idx = np.arange(total_rows)\n",
    "    train_mask = np.isin(all_idx, valid_idx, invert=True)\n",
    "    train_idx = all_idx[train_mask]\n",
    "    return train_idx, valid_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_valid_split(X, y, train_idx, valid_idx):\n",
    "    \"\"\"Split into train/test sets, based on index location.\"\"\"\n",
    "    X_train = X.copy().iloc[train_idx]\n",
    "    y_train = y.copy().iloc[train_idx]\n",
    "    X_valid = X.copy().iloc[valid_idx]\n",
    "    y_valid = y.copy().iloc[valid_idx]\n",
    "    return X_train, y_train, X_valid, y_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess(X_train, X_valid, y_train, y_valid, kmeans=True, pca=True, target_log=True):\n",
    "    \"\"\"Ensures preprocessing without data leakage.\"\"\"\n",
    "    ncols = X_train.shape[1]\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = X_train.values, X_valid.values, y_train.values, y_valid.values\n",
    "    \n",
    "    X_train, X_valid = scale(X_train, X_valid)\n",
    "    \n",
    "    if pca is True:\n",
    "        X_train, X_valid = apply_pca(X_train, X_valid, ncols=ncols)\n",
    "        \n",
    "    if kmeans is True: \n",
    "        X_train, X_valid = apply_k_means(X_train, X_valid, ncols=ncols)\n",
    "    \n",
    "    if target_log:\n",
    "        y_train = np.log(y_train)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scale(X_train, X_valid):\n",
    "    \"\"\"Fits X_train and transforms X_valid.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_valid = scaler.transform(X_valid)\n",
    "    return X_train, X_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_k_means(X_train, X_valid, ncols, n_clusters=3):\n",
    "    \"\"\"Fits X_train and predicts on X_valid.\"\"\"\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    X_train_clusters = km.fit(X_train[:, :ncols]).labels_.reshape(-1, 1)\n",
    "    X_valid_clusters = km.predict(X_valid[:, :ncols]).reshape(-1, 1)\n",
    "    \n",
    "    X_train = np.concatenate((X_train, X_train_clusters), axis=1)\n",
    "    X_valid = np.concatenate((X_valid, X_valid_clusters), axis=1)\n",
    "\n",
    "    return X_train, X_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_pca(X_train, X_valid, ncols, n_components=3):\n",
    "    \"\"\"Fits X_train and transforms X_valid.\"\"\"\n",
    "    pca = PCA(n_components=n_components)    \n",
    "    pc_X_train = pca.fit_transform(X_train[:, :ncols])\n",
    "    pc_X_valid = pca.transform(X_valid[:, :ncols])\n",
    "    \n",
    "    X_train = np.concatenate((X_train, pc_X_train), axis=1)\n",
    "    X_valid = np.concatenate((X_valid, pc_X_valid), axis=1)\n",
    "    \n",
    "    return X_train, X_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_regression(y_test, y_pred, plot=False):\n",
    "    \"\"\"Evaluate performance based on MAE and RMSE.\"\"\"\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    if plot is True:\n",
    "        print(f'''MAE:\\t{mae}\\nRMSE:\\t{rmse}''')\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.scatter(y_test, y_pred, alpha=0.4)\n",
    "        plt.plot(*2*[np.arange(0,500000)], color='r', ls='--')\n",
    "        plt.xlabel('y true')\n",
    "        plt.ylabel('y pred')\n",
    "        plt.ylim(0, 500000)\n",
    "        plt.xlim(0, 500000)\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = data[x_cols].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = data['SalePrice'].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_options = [\n",
    "    {\n",
    "        \"kmeans\": False, \"pca\": False,\n",
    "    },\n",
    "    {\n",
    "        \"kmeans\": True, \"pca\": False,\n",
    "    },\n",
    "    {\n",
    "        \"kmeans\": False, \"pca\": True,\n",
    "    },\n",
    "    {\n",
    "        \"kmeans\": True, \"pca\": True,\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Use clusters as feature in a linear model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for kwargs in cv_options:\n",
    "    print(kwargs)\n",
    "    metrics = perform_cross_validation(X, y, model, cv_folds=10, **kwargs)\n",
    "    result = pd.DataFrame(data=metrics, index=[str(kwargs)])\n",
    "    results = pd.concat((results, result), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(data=results, vmin=0, vmax=40000, annot=True, fmt='g', cmap='RdYlGn_r')\n",
    "plt.title(\"Metric performance\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Use clusters as feature in a NON-linear model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=500, max_features=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for kwargs in cv_options:\n",
    "    metrics = perform_cross_validation(X, y, model, cv_folds=10, **kwargs)\n",
    "    result = pd.DataFrame(data=metrics, index=[str(kwargs)])\n",
    "    results = pd.concat((results, result), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(data=results, vmin=0, vmax=40000, annot=True, fmt='g', cmap='RdYlGn_r')\n",
    "plt.title(\"Metric performance\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "Linear regression explodes when using PCA as features!\n",
    "\n",
    "Using k-means as feature improves performance minimally, at least for this specific data set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-mentorship",
   "language": "python",
   "name": "ds-mentorship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}